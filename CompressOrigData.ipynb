{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a61ab06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import utils\n",
    "utils.widen_ipython_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbcb8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "MAIN_PATH = \"/home/mahesh/Desktop/ML/kaggle/amex/\"\n",
    "\n",
    "# Data\n",
    "PATH_TO_DATA                = MAIN_PATH + \"data/\"\n",
    "PATH_TO_PROCESSED2_DATA     = PATH_TO_DATA + \"processed2/\"\n",
    "PATH_TO_PROCESSED3_DATA     = PATH_TO_DATA + \"processed3/\"\n",
    "PATH_TO_PROCESSED4_DATA     = PATH_TO_DATA + \"processed4/\"\n",
    "\n",
    "FILENAME_TRAIN_DATA_CSV     = PATH_TO_DATA + \"orig/train_data.csv\"\n",
    "FILENAME_TRAIN_LABELS_CSV   = PATH_TO_DATA + \"orig/train_labels.csv\"\n",
    "FILENAME_TRAIN_DATA_FEATHER = PATH_TO_DATA + \"orig/train_data.f\"     \n",
    "FILENAME_TEST_DATA_CSV      = PATH_TO_DATA + \"orig/test_data.csv\"\n",
    "\n",
    "# Processed data\n",
    "#FILENAME_CID_MAP                      = PATH_TO_PROCESSED_DATA + \"cid_map.csv\"\n",
    "FILENAME_TRAIN_PROCESSED2_DATA_FEATHER   = PATH_TO_PROCESSED2_DATA + \"train_data.f\"\n",
    "FILENAME_TRAIN_PROCESSED2_LABELS_FEATHER = PATH_TO_PROCESSED2_DATA + \"train_labels.f\"\n",
    "FILENAME_TRAIN_PROCESSED2_DATA_CAT_NOCHANGE_FEATHER  = PATH_TO_PROCESSED2_DATA + \"train_data_cat_nochange.f\"\n",
    "FILENAME_TEST_PROCESSED2_DATA_FEATHER    = PATH_TO_PROCESSED2_DATA + \"test_data.f\"\n",
    "FILENAME_TEST_PROCESSED2_DATA_CAT_NOCHANGE_FEATHER   = PATH_TO_PROCESSED2_DATA + \"test_data_cat_nochange.f\"\n",
    "\n",
    "FILENAME_TEST_CUSTOMER_HASHES  = PATH_TO_PROCESSED2_DATA + \"test_customer_hashes_data.pq\"\n",
    "FILENAME_TEST_CID_OLD_NEW_MAP  = PATH_TO_PROCESSED2_DATA + \"test_cid_old_new_map.f\"\n",
    "\n",
    "\n",
    "FILENAME_TRAIN_PROCESSED3_DATA_PARAQUET  = PATH_TO_PROCESSED3_DATA + \"train_data.pq\"\n",
    "FILENAME_LGBM_FEATURE_IMPORTANCE = PATH_TO_PROCESSED4_DATA + \"feature_imp.pkl\"\n",
    "\n",
    "PATH_TO_GRU_NAN_EMBEDDINGS_DATA = PATH_TO_DATA + \"gru_nan_embeddings_full/\"\n",
    "FILENAME_TRAIN_PROCESSED_GRU_NAN_EMBEDDINGS_FEATHER = PATH_TO_GRU_NAN_EMBEDDINGS_DATA + \"train_data.f\"\n",
    "\n",
    "PATH_TO_RNN_NAN_EMBEDDINGS_NN_STATS_DATA = PATH_TO_DATA + \"rnn_nn/\"\n",
    "FILENAME_TRAIN_RNN_NN_DATA_FEATHER = PATH_TO_RNN_NAN_EMBEDDINGS_NN_STATS_DATA + \"train_nn_data.f\"\n",
    "FILENAME_TRAIN_RNN_RNN_DATA_FEATHER = PATH_TO_RNN_NAN_EMBEDDINGS_NN_STATS_DATA + \"train_rnn_data.f\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4491c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_time_cols = set(['customer_ID', 'S_2'])\n",
    "cat_cols = set(['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68'])\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed3d969",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "    1. Read FULL CSV into DF (Data-Frame).  \n",
    "    2. Use low-memory representation for CIDs, date-time, categorical data and numerical data. This should reduce memory usage.  \n",
    "    3. Save the low-memory representation DF to Feather Format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c331b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-19 11:15:41.580601\n",
      "2022-08-19 11:17:30.079699\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5531451 entries, 0 to 5531450\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: float64(185), int64(1), object(4)\n",
      "memory usage: 9.2 GB\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "# Read from Feather\n",
    "#train_df = pd.read_feather(FILENAME_TRAIN_DATA_FEATHER)\n",
    "# Read from CSV\n",
    "train_df = pd.read_csv(FILENAME_TRAIN_DATA_CSV)\n",
    "print(datetime.datetime.now())\n",
    "train_df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a280e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here we are messing with both categorical and numerical data\n",
    "#\n",
    "\n",
    "train_df['customer_ID'] = train_df['customer_ID'].str[-16:].apply(lambda x:int(x,16)).astype('int64')\n",
    "train_df['S_2'] = pd.to_datetime( train_df['S_2'] )\n",
    "\n",
    "\n",
    "for c in train_df.columns:\n",
    "    if c in id_time_cols: continue\n",
    "    if c in cat_cols:\n",
    "        train_df[c] = train_df[c].astype('category')\n",
    "    elif str( train_df[c].dtype )=='int64':\n",
    "        train_df[c] = train_df[c].astype('int32')\n",
    "    elif str( train_df[c].dtype )=='float64':\n",
    "        train_df[c] = train_df[c].astype('float32')\n",
    "\n",
    "train_df.to_feather(FILENAME_TRAIN_PROCESSED_DATA_FEATHER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e98a2af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-30 08:53:15.358187\n",
      "2022-07-30 08:53:16.502071\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5531451 entries, 0 to 5531450\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 3.8 GB\n"
     ]
    }
   ],
   "source": [
    "del train_df\n",
    "gc.collect()\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "# Read from Feather\n",
    "train_df = pd.read_feather(FILENAME_TRAIN_PROCESSED_DATA_FEATHER)\n",
    "print(datetime.datetime.now())\n",
    "train_df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "778b3e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Edit the customer IDs of the label data\n",
    "#\n",
    "\n",
    "train_labels_df = pd.read_csv(FILENAME_TRAIN_LABELS_CSV)\n",
    "\n",
    "train_labels_df['customer_ID'] = train_labels_df['customer_ID'].str[-16:].apply(lambda x:int(x,16)).astype('int64')\n",
    "\n",
    "train_labels_df.to_feather(FILENAME_TRAIN_PROCESSED2_LABELS_FEATHER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d694d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-19 11:19:07.562303\n",
      "2022-08-19 11:19:11.129219\n",
      "2022-08-19 11:21:01.605689\n",
      "2022-08-19 11:21:05.198479\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here we are messing only with numerical data, and leaving categorical data unchanged.\n",
    "#\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "train_df['customer_ID'] = train_df['customer_ID'].str[-16:].apply(lambda x:int(x,16)).astype('int64')\n",
    "train_df['S_2'] = pd.to_datetime( train_df['S_2'] )\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "for c in train_df.columns:\n",
    "    if c in id_time_cols: continue\n",
    "    if c in cat_cols:\n",
    "        # train_df[c] = train_df[c].astype('category')\n",
    "        pass\n",
    "    elif str( train_df[c].dtype )=='int64':\n",
    "        train_df[c] = train_df[c].astype('int32')\n",
    "    elif str( train_df[c].dtype )=='float64':\n",
    "        train_df[c] = train_df[c].astype('float32')\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "train_df.to_feather(FILENAME_TRAIN_PROCESSED2_DATA_CAT_NOCHANGE_FEATHER)\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "#del train_df\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f98c557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-19 11:25:57.603904\n",
      "2022-08-19 11:26:00.184262\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5531451 entries, 0 to 5531450\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(176), float64(9), int32(1), int64(1), object(2)\n",
      "memory usage: 4.7 GB\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "# Read from Feather\n",
    "train_df = pd.read_feather(FILENAME_TRAIN_PROCESSED2_DATA_CAT_NOCHANGE_FEATHER)\n",
    "print(datetime.datetime.now())\n",
    "train_df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a249bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_time_cols = set(['customer_ID', 'S_2'])\n",
    "cat_cols = set(['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68'])\n",
    "\n",
    "def compress_df(df, change_cat_data = False):\n",
    "    df['customer_ID'] = df['customer_ID'].str[-16:].apply(lambda x:int(x,16)).astype('int64')\n",
    "    df['S_2'] = pd.to_datetime( df['S_2'] )\n",
    "    for c in df.columns:\n",
    "        if c in id_time_cols: continue\n",
    "        if ((c in cat_cols) and (change_cat_data)):\n",
    "            df[c] = df[c].astype('category')\n",
    "        elif str( df[c].dtype )=='int64':\n",
    "            df[c] = df[c].astype('int32')\n",
    "        elif str( df[c].dtype )=='float64':\n",
    "            df[c] = df[c].astype('float32')\n",
    "    return df\n",
    "\n",
    "def compress_train_data_for_gru(FILENAME_CSV, change_cat_data):\n",
    "    chunksize = 200000\n",
    "    compressed_full_df = None\n",
    "    count = 0\n",
    "    with pd.read_csv(FILENAME_CSV, chunksize=chunksize) as reader:\n",
    "        for chunk_df in reader:\n",
    "            utils.pt(f'Processing chunk {count}')\n",
    "            #chunk_df.info()\n",
    "            compressed_chunk_df = compress_df(chunk_df, change_cat_data)\n",
    "            #compressed_chunk_df.info()\n",
    "            if (compressed_full_df is None):\n",
    "                compressed_full_df = compressed_chunk_df\n",
    "            else:\n",
    "                compressed_full_df = pd.concat([compressed_full_df,compressed_chunk_df],ignore_index = True)\n",
    "            utils.gc_l([compressed_chunk_df])\n",
    "            #chunk_df.info()\n",
    "            count += 1\n",
    "            compressed_full_df.info(memory_usage=\"deep\")\n",
    "    return compressed_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7177be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-24 14:34:44.064258 : Processing chunk 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 167.1 MB\n",
      "2022-08-24 14:34:52.018814 : Processing chunk 1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400000 entries, 0 to 399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 334.2 MB\n",
      "2022-08-24 14:34:59.884538 : Processing chunk 2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600000 entries, 0 to 599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 501.3 MB\n",
      "2022-08-24 14:35:08.205532 : Processing chunk 3\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800000 entries, 0 to 799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 668.4 MB\n",
      "2022-08-24 14:35:17.099089 : Processing chunk 4\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 835.5 MB\n",
      "2022-08-24 14:35:26.028631 : Processing chunk 5\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200000 entries, 0 to 1199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 1002.7 MB\n",
      "2022-08-24 14:35:35.369629 : Processing chunk 6\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1400000 entries, 0 to 1399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 1.1 GB\n",
      "2022-08-24 14:35:44.700826 : Processing chunk 7\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 1.3 GB\n",
      "2022-08-24 14:35:54.300560 : Processing chunk 8\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1800000 entries, 0 to 1799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 1.5 GB\n",
      "2022-08-24 14:36:03.770708 : Processing chunk 9\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000000 entries, 0 to 1999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 1.6 GB\n",
      "2022-08-24 14:36:13.431137 : Processing chunk 10\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2200000 entries, 0 to 2199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 1.8 GB\n",
      "2022-08-24 14:36:23.518168 : Processing chunk 11\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400000 entries, 0 to 2399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 2.0 GB\n",
      "2022-08-24 14:36:33.615389 : Processing chunk 12\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2600000 entries, 0 to 2599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 2.1 GB\n",
      "2022-08-24 14:36:43.878478 : Processing chunk 13\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2800000 entries, 0 to 2799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 2.3 GB\n",
      "2022-08-24 14:36:54.844891 : Processing chunk 14\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000000 entries, 0 to 2999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 2.4 GB\n",
      "2022-08-24 14:37:05.523283 : Processing chunk 15\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3200000 entries, 0 to 3199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 2.6 GB\n",
      "2022-08-24 14:37:16.732512 : Processing chunk 16\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3400000 entries, 0 to 3399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 2.8 GB\n",
      "2022-08-24 14:37:27.559984 : Processing chunk 17\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3600000 entries, 0 to 3599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 2.9 GB\n",
      "2022-08-24 14:37:38.977858 : Processing chunk 18\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3800000 entries, 0 to 3799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 3.1 GB\n",
      "2022-08-24 14:37:50.292349 : Processing chunk 19\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000000 entries, 0 to 3999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 3.3 GB\n",
      "2022-08-24 14:38:02.117941 : Processing chunk 20\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4200000 entries, 0 to 4199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 3.4 GB\n",
      "2022-08-24 14:38:13.543436 : Processing chunk 21\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4400000 entries, 0 to 4399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 3.6 GB\n",
      "2022-08-24 14:38:25.264073 : Processing chunk 22\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600000 entries, 0 to 4599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 3.8 GB\n",
      "2022-08-24 14:38:37.328023 : Processing chunk 23\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4800000 entries, 0 to 4799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 3.9 GB\n",
      "2022-08-24 14:38:48.840260 : Processing chunk 24\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000000 entries, 0 to 4999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 4.1 GB\n",
      "2022-08-24 14:39:00.674622 : Processing chunk 25\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5200000 entries, 0 to 5199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 4.2 GB\n",
      "2022-08-24 14:39:13.220705 : Processing chunk 26\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5400000 entries, 0 to 5399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 4.4 GB\n",
      "2022-08-24 14:39:25.512976 : Processing chunk 27\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5600000 entries, 0 to 5599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 4.6 GB\n",
      "2022-08-24 14:39:38.023592 : Processing chunk 28\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5800000 entries, 0 to 5799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 4.7 GB\n",
      "2022-08-24 14:39:50.005305 : Processing chunk 29\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000000 entries, 0 to 5999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 4.9 GB\n",
      "2022-08-24 14:40:02.258648 : Processing chunk 30\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6200000 entries, 0 to 6199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 5.1 GB\n",
      "2022-08-24 14:40:15.278398 : Processing chunk 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6400000 entries, 0 to 6399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 5.2 GB\n",
      "2022-08-24 14:40:27.731611 : Processing chunk 32\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6600000 entries, 0 to 6599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 5.4 GB\n",
      "2022-08-24 14:40:40.338166 : Processing chunk 33\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6800000 entries, 0 to 6799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 5.5 GB\n",
      "2022-08-24 14:40:53.854456 : Processing chunk 34\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000000 entries, 0 to 6999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 5.7 GB\n",
      "2022-08-24 14:41:06.969363 : Processing chunk 35\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7200000 entries, 0 to 7199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 5.9 GB\n",
      "2022-08-24 14:41:20.089630 : Processing chunk 36\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7400000 entries, 0 to 7399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 6.0 GB\n",
      "2022-08-24 14:41:33.302785 : Processing chunk 37\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7600000 entries, 0 to 7599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 6.2 GB\n",
      "2022-08-24 14:41:46.604693 : Processing chunk 38\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7800000 entries, 0 to 7799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 6.4 GB\n",
      "2022-08-24 14:42:00.034269 : Processing chunk 39\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000000 entries, 0 to 7999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 6.5 GB\n",
      "2022-08-24 14:42:14.068134 : Processing chunk 40\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8200000 entries, 0 to 8199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 6.7 GB\n",
      "2022-08-24 14:42:28.189028 : Processing chunk 41\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8400000 entries, 0 to 8399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 6.9 GB\n",
      "2022-08-24 14:42:42.465716 : Processing chunk 42\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8600000 entries, 0 to 8599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 7.0 GB\n",
      "2022-08-24 14:42:57.829074 : Processing chunk 43\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8800000 entries, 0 to 8799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 7.2 GB\n",
      "2022-08-24 14:43:12.973414 : Processing chunk 44\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9000000 entries, 0 to 8999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 7.3 GB\n",
      "2022-08-24 14:43:28.417457 : Processing chunk 45\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9200000 entries, 0 to 9199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 7.5 GB\n",
      "2022-08-24 14:43:44.423805 : Processing chunk 46\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9400000 entries, 0 to 9399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 7.7 GB\n",
      "2022-08-24 14:43:59.865019 : Processing chunk 47\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9600000 entries, 0 to 9599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 7.8 GB\n",
      "2022-08-24 14:44:16.147238 : Processing chunk 48\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9800000 entries, 0 to 9799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 8.0 GB\n",
      "2022-08-24 14:44:32.445879 : Processing chunk 49\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 0 to 9999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 8.2 GB\n",
      "2022-08-24 14:44:48.457308 : Processing chunk 50\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10200000 entries, 0 to 10199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 8.3 GB\n",
      "2022-08-24 14:45:04.538427 : Processing chunk 51\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10400000 entries, 0 to 10399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 8.5 GB\n",
      "2022-08-24 14:45:20.698632 : Processing chunk 52\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10600000 entries, 0 to 10599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 8.6 GB\n",
      "2022-08-24 14:45:37.555741 : Processing chunk 53\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10800000 entries, 0 to 10799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 8.8 GB\n",
      "2022-08-24 14:45:53.960442 : Processing chunk 54\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11000000 entries, 0 to 10999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 9.0 GB\n",
      "2022-08-24 14:46:10.444076 : Processing chunk 55\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11200000 entries, 0 to 11199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 9.1 GB\n",
      "2022-08-24 14:46:26.894122 : Processing chunk 56\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11363762 entries, 0 to 11363761\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: datetime64[ns](1), float32(185), int32(1), int64(1), object(2)\n",
      "memory usage: 9.3 GB\n"
     ]
    }
   ],
   "source": [
    "test_df = compress_train_data_for_gru(FILENAME_TEST_DATA_CSV, False)\n",
    "utils.pt('Writing file.')\n",
    "test_df.to_feather(FILENAME_TEST_PROCESSED2_DATA_CAT_NOCHANGE_FEATHER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e788772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-24 14:54:51.690409 : Processing chunk 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 140.2 MB\n",
      "2022-08-24 14:54:59.444090 : Processing chunk 1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400000 entries, 0 to 399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 280.4 MB\n",
      "2022-08-24 14:55:07.149084 : Processing chunk 2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600000 entries, 0 to 599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 420.6 MB\n",
      "2022-08-24 14:55:15.784973 : Processing chunk 3\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800000 entries, 0 to 799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 560.8 MB\n",
      "2022-08-24 14:55:23.814193 : Processing chunk 4\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 701.0 MB\n",
      "2022-08-24 14:55:31.863852 : Processing chunk 5\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200000 entries, 0 to 1199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 841.1 MB\n",
      "2022-08-24 14:55:40.664030 : Processing chunk 6\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1400000 entries, 0 to 1399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 981.3 MB\n",
      "2022-08-24 14:55:49.300288 : Processing chunk 7\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 1.1 GB\n",
      "2022-08-24 14:55:58.034303 : Processing chunk 8\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1800000 entries, 0 to 1799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 1.2 GB\n",
      "2022-08-24 14:56:07.051625 : Processing chunk 9\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000000 entries, 0 to 1999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 1.4 GB\n",
      "2022-08-24 14:56:16.646199 : Processing chunk 10\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2200000 entries, 0 to 2199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 1.5 GB\n",
      "2022-08-24 14:56:26.002345 : Processing chunk 11\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400000 entries, 0 to 2399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 1.6 GB\n",
      "2022-08-24 14:56:34.769792 : Processing chunk 12\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2600000 entries, 0 to 2599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 1.8 GB\n",
      "2022-08-24 14:56:43.407390 : Processing chunk 13\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2800000 entries, 0 to 2799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 1.9 GB\n",
      "2022-08-24 14:56:52.213495 : Processing chunk 14\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000000 entries, 0 to 2999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 2.1 GB\n",
      "2022-08-24 14:57:01.104032 : Processing chunk 15\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3200000 entries, 0 to 3199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 2.2 GB\n",
      "2022-08-24 14:57:09.943896 : Processing chunk 16\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3400000 entries, 0 to 3399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 2.3 GB\n",
      "2022-08-24 14:57:18.984617 : Processing chunk 17\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3600000 entries, 0 to 3599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 2.5 GB\n",
      "2022-08-24 14:57:28.126418 : Processing chunk 18\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3800000 entries, 0 to 3799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 2.6 GB\n",
      "2022-08-24 14:57:37.295256 : Processing chunk 19\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000000 entries, 0 to 3999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 2.7 GB\n",
      "2022-08-24 14:57:46.582266 : Processing chunk 20\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4200000 entries, 0 to 4199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 2.9 GB\n",
      "2022-08-24 14:57:55.933918 : Processing chunk 21\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4400000 entries, 0 to 4399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 3.0 GB\n",
      "2022-08-24 14:58:05.368973 : Processing chunk 22\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600000 entries, 0 to 4599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 3.1 GB\n",
      "2022-08-24 14:58:14.803017 : Processing chunk 23\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4800000 entries, 0 to 4799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 3.3 GB\n",
      "2022-08-24 14:58:24.543532 : Processing chunk 24\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000000 entries, 0 to 4999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 3.4 GB\n",
      "2022-08-24 14:58:34.298444 : Processing chunk 25\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5200000 entries, 0 to 5199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 3.6 GB\n",
      "2022-08-24 14:58:44.339308 : Processing chunk 26\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5400000 entries, 0 to 5399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 3.7 GB\n",
      "2022-08-24 14:58:55.104305 : Processing chunk 27\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5600000 entries, 0 to 5599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 3.8 GB\n",
      "2022-08-24 14:59:06.501573 : Processing chunk 28\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5800000 entries, 0 to 5799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 4.0 GB\n",
      "2022-08-24 14:59:17.809137 : Processing chunk 29\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000000 entries, 0 to 5999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 4.1 GB\n",
      "2022-08-24 14:59:29.759003 : Processing chunk 30\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6200000 entries, 0 to 6199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 4.2 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-24 14:59:41.793906 : Processing chunk 31\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6400000 entries, 0 to 6399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 4.4 GB\n",
      "2022-08-24 14:59:54.037128 : Processing chunk 32\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6600000 entries, 0 to 6599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 4.5 GB\n",
      "2022-08-24 15:00:05.337011 : Processing chunk 33\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6800000 entries, 0 to 6799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 4.7 GB\n",
      "2022-08-24 15:00:16.475139 : Processing chunk 34\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000000 entries, 0 to 6999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 4.8 GB\n",
      "2022-08-24 15:00:27.912352 : Processing chunk 35\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7200000 entries, 0 to 7199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 4.9 GB\n",
      "2022-08-24 15:00:39.346088 : Processing chunk 36\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7400000 entries, 0 to 7399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 5.1 GB\n",
      "2022-08-24 15:00:50.749878 : Processing chunk 37\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7600000 entries, 0 to 7599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 5.2 GB\n",
      "2022-08-24 15:01:02.263611 : Processing chunk 38\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7800000 entries, 0 to 7799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 5.3 GB\n",
      "2022-08-24 15:01:14.372885 : Processing chunk 39\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000000 entries, 0 to 7999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 5.5 GB\n",
      "2022-08-24 15:01:26.284008 : Processing chunk 40\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8200000 entries, 0 to 8199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 5.6 GB\n",
      "2022-08-24 15:01:38.370142 : Processing chunk 41\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8400000 entries, 0 to 8399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 5.7 GB\n",
      "2022-08-24 15:01:50.728384 : Processing chunk 42\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8600000 entries, 0 to 8599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 5.9 GB\n",
      "2022-08-24 15:02:02.915137 : Processing chunk 43\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8800000 entries, 0 to 8799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 6.0 GB\n",
      "2022-08-24 15:02:15.157000 : Processing chunk 44\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9000000 entries, 0 to 8999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 6.2 GB\n",
      "2022-08-24 15:02:28.042875 : Processing chunk 45\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9200000 entries, 0 to 9199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 6.3 GB\n",
      "2022-08-24 15:02:40.891452 : Processing chunk 46\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9400000 entries, 0 to 9399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 6.4 GB\n",
      "2022-08-24 15:02:53.960240 : Processing chunk 47\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9600000 entries, 0 to 9599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 6.6 GB\n",
      "2022-08-24 15:03:07.324159 : Processing chunk 48\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9800000 entries, 0 to 9799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 6.7 GB\n",
      "2022-08-24 15:03:20.690630 : Processing chunk 49\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 0 to 9999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 6.8 GB\n",
      "2022-08-24 15:03:34.340227 : Processing chunk 50\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10200000 entries, 0 to 10199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 7.0 GB\n",
      "2022-08-24 15:03:48.319462 : Processing chunk 51\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10400000 entries, 0 to 10399999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 7.1 GB\n",
      "2022-08-24 15:04:02.464250 : Processing chunk 52\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10600000 entries, 0 to 10599999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 7.3 GB\n",
      "2022-08-24 15:04:16.978336 : Processing chunk 53\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10800000 entries, 0 to 10799999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 7.4 GB\n",
      "2022-08-24 15:04:31.244779 : Processing chunk 54\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11000000 entries, 0 to 10999999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 7.5 GB\n",
      "2022-08-24 15:04:45.693536 : Processing chunk 55\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11200000 entries, 0 to 11199999\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 7.7 GB\n",
      "2022-08-24 15:05:00.026090 : Processing chunk 56\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11363762 entries, 0 to 11363761\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: category(11), datetime64[ns](1), float32(176), int32(1), int64(1)\n",
      "memory usage: 7.8 GB\n",
      "2022-08-24 15:05:10.650255 : Writing file.\n"
     ]
    }
   ],
   "source": [
    "test_df = compress_train_data_for_gru(FILENAME_TEST_DATA_CSV, True)\n",
    "utils.pt('Writing file.')\n",
    "test_df.to_feather(FILENAME_TEST_PROCESSED2_DATA_FEATHER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44699f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cids = pd.read_parquet(FILENAME_TEST_CUSTOMER_HASHES)\n",
    "test_cids = test_cids.drop_duplicates().sort_index().reset_index()\n",
    "test_cids.rename(columns = {'customer_ID':'customer_ID_orig'}, inplace = True)\n",
    "test_cids['customer_ID'] = test_cids['customer_ID_orig'].str[-16:].apply(lambda x:int(x,16)).astype('int64')\n",
    "test_cids.to_feather(FILENAME_TEST_CID_OLD_NEW_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc8926ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-07 17:01:43.216316 : NN feature engineering\n",
      "2022-09-07 17:01:46.922237 : Starting training feature engineer 1...\n",
      "2022-09-07 17:01:53.684609 : Starting training feature engineer 2...\n",
      "2022-09-07 17:01:53.976799 : Processing categorical features ...\n",
      "2022-09-07 17:01:53.976848 : Processing feature/s ['B_30', 'D_114', 'D_116'] ... \n",
      "2022-09-07 17:01:55.234546 : Processing feature/s ['D_117', 'D_120', 'D_126'] ... \n",
      "2022-09-07 17:01:56.611039 : Processing feature/s ['D_66', 'D_68', 'D_63'] ... \n",
      "2022-09-07 17:01:57.959440 : Processing feature/s ['D_64'] ... \n",
      "2022-09-07 17:01:58.890741 : Joining aggregate data ...\n",
      "2022-09-07 17:01:58.891612 : Processing numerical features ...\n",
      "2022-09-07 17:01:58.891645 : Processing feature/s ['B_6', 'S_6', 'B_13', 'D_58', 'D_60', 'B_15', 'B_16', 'B_19', 'D_69', 'D_71'] ... \n",
      "2022-09-07 17:02:00.828916 : Processing feature/s ['D_73', 'P_4', 'D_76', 'B_25', 'R_8', 'R_9', 'D_80', 'B_27', 'D_81', 'D_82'] ... \n",
      "2022-09-07 17:02:02.922530 : Processing feature/s ['S_17', 'R_12', 'R_13', 'D_83', 'R_14', 'R_15', 'D_84', 'B_29', 'S_18', 'D_86'] ... \n",
      "2022-09-07 17:02:05.757014 : Processing feature/s ['D_87', 'R_17', 'R_18', 'D_88', 'B_31', 'S_19', 'R_19', 'B_32', 'S_20', 'R_20'] ... \n",
      "2022-09-07 17:02:09.669101 : Processing feature/s ['R_21', 'D_89', 'R_22', 'R_23', 'D_92', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96'] ... \n",
      "2022-09-07 17:02:15.366164 : Processing feature/s ['D_102', 'D_103', 'D_104', 'D_106', 'D_107', 'B_36', 'R_26', 'D_108', 'D_109', 'D_110'] ... \n",
      "2022-09-07 17:02:23.674628 : Processing feature/s ['D_111', 'B_39', 'D_113', 'D_115', 'D_119', 'D_125', 'D_127', 'B_41', 'B_42', 'D_130'] ... \n",
      "2022-09-07 17:02:35.571935 : Processing feature/s ['D_133', 'R_28', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141'] ... \n",
      "2022-09-07 17:02:51.059967 : Processing feature/s ['D_142', 'D_143', 'D_145'] ... \n",
      "2022-09-07 17:03:09.721722 : Joining aggregate data ...\n",
      "2022-09-07 17:03:09.723056 : Merging numerical and categorical features ...\n",
      "[]\n",
      "2022-09-07 17:03:32.006747 : RNN feature engineering\n",
      "2022-09-07 17:03:37.709849 : Feature engineering complete.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 1. Read LGBM pre-processed(pp) data, handle NaNs and write only the unimportant features back to file.\n",
    "# 2. Read RNN  pre-processed(pp) data, write only th2e unimportant features back to file.\n",
    "#\n",
    "\n",
    "CAT_FEATURES = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "\n",
    "IMP_FEATURES_THRESHOLD = 94\n",
    "\n",
    "# Read feature importance file\n",
    "def read_feature_importance():\n",
    "    with open(FILENAME_LGBM_FEATURE_IMPORTANCE, 'rb') as f: \n",
    "        f_imp = pickle.load(f)    \n",
    "    return (f_imp[0], f_imp[1])\n",
    "\n",
    "# Split features into important and unimportant features \n",
    "def imp_unimp_features(f_p_imp_dict):\n",
    "    \n",
    "    # first 95 are imp features, rest are un-imp features\n",
    "    \n",
    "    imp_f   = []\n",
    "    unimp_f = []\n",
    "    th = IMP_FEATURES_THRESHOLD\n",
    "    c = 0\n",
    "    for k in f_p_imp_dict.keys():\n",
    "        if (c <= th):\n",
    "            imp_f.append(k)\n",
    "        else:\n",
    "            unimp_f.append(k)\n",
    "        c += 1\n",
    "        \n",
    "    # Cat features appear in front\n",
    "    imp_f.sort(key=(lambda x: 0 if (x in CAT_FEATURES) else 1))\n",
    "    unimp_f.sort(key=(lambda x: 0 if (x in CAT_FEATURES) else 1))\n",
    "        \n",
    "    return (imp_f, unimp_f)\n",
    "\n",
    "def does_s_begin_with_one_of_l(s, l):\n",
    "    for i in l:\n",
    "        if s.startswith(i): return True\n",
    "    return False\n",
    "\n",
    "TARGET_LABEL      = 'target'\n",
    "CUSTOMER_ID_LABEL = \"customer_ID\"\n",
    "TIME_LABEL        = 'S_2'\n",
    "\n",
    "#\n",
    "# The below function is copy from GRU_train_eval, but we don't want to treat NaNs yet since filling NaN values will change the stats\n",
    "# , so we wait till later to fill NaNs. Also, we don't add padding columns to each customer to have 13 months of data, or we don't \n",
    "# group the rows by cid.\n",
    "#\n",
    "def feature_engineer_rnn(train, edit_cid_time = False, fill_nan = False, PAD_CUSTOMER_TO_13_ROWS = False, targets = None):\n",
    "    \n",
    "    utils.pt('Starting training feature engineer 1...')\n",
    "    \n",
    "    features = [col for col in train.columns if col not in [CUSTOMER_ID_LABEL, TARGET_LABEL]]\n",
    "    \n",
    "    # REDUCE STRING COLUMNS \n",
    "    # from 64 bytes to 8 bytes, and 10 bytes to 3 bytes respectively\n",
    "    #train['customer_ID'] = train['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
    "    if edit_cid_time:\n",
    "        train['customer_ID'] = train['customer_ID'].str[-16:].apply(lambda x:int(x,16)).astype('int64')\n",
    "        train.S_2 = pd.to_datetime( train.S_2 )\n",
    "    \n",
    "    train['year'] = (train.S_2.dt.year-2000).astype('int8')\n",
    "    train['month'] = (train.S_2.dt.month).astype('int8')\n",
    "    train['day'] = (train.S_2.dt.day).astype('int8')\n",
    "    del train['S_2']\n",
    "\n",
    "    \n",
    "    PARTIAL_CATS = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_66', 'D_68']\n",
    "    CATS = []\n",
    "    OFFSETS = [1,0,1,1,2,1,2,1,1] #2 minus minimal value in full train csv\n",
    "    # then 0 will be padding, 1 will be NAN, 2,3,4,etc will be values\n",
    "    for c,s in zip(PARTIAL_CATS,OFFSETS):\n",
    "        if c in features:\n",
    "            train[c] = train[c] + s\n",
    "            # train[c] = train[c].fillna(0).astype('int8')\n",
    "            #if (fill_nan): train[c] = train[c].fillna(0)\n",
    "            CATS.append(c)\n",
    "    \n",
    "    # LABEL ENCODE CAT COLUMNS (and reduce to 1 byte)\n",
    "    # with 0: padding, 1: nan, 2,3,4,etc: values\n",
    "    if ('D_63' in features):\n",
    "        d_63_map = {'CL':1, 'CO':2, 'CR':3, 'XL':4, 'XM':5, 'XZ':6}\n",
    "        #train['D_63'] = train.D_63.map(d_63_map).fillna(0).astype('int8')\n",
    "        train['D_63'] = train.D_63.map(d_63_map)\n",
    "        CATS.append('D_63')\n",
    "\n",
    "    if ('D_64' in features):\n",
    "        d_64_map = {'-1':1,'O':2, 'R':3, 'U':4}\n",
    "        #train['D_64'] = train.D_64.map(d_64_map).fillna(0).astype('int8')\n",
    "        train['D_64'] = train.D_64.map(d_64_map)\n",
    "        CATS.append('D_64')\n",
    "    \n",
    "    # ADD NEW FEATURES HERE\n",
    "    # EXAMPLE: train['feature_189'] = etc etc etc\n",
    "    # EXAMPLE: train['feature_190'] = etc etc etc\n",
    "    # IF CATEGORICAL, THEN ADD TO CATS WITH: CATS += ['feaure_190'] etc etc etc\n",
    "    \n",
    "    # REDUCE MEMORY DTYPE\n",
    "    SKIP = ['customer_ID','year','month','day']\n",
    "    for c in train.columns:\n",
    "        if c in SKIP: continue\n",
    "        if str( train[c].dtype )=='int64':\n",
    "            train[c] = train[c].astype('int32')\n",
    "        if str( train[c].dtype )=='float64':\n",
    "            train[c] = train[c].astype('float32')\n",
    "    \n",
    "    # PAD ROWS SO EACH CUSTOMER HAS 13 ROWS\n",
    "#     if PAD_CUSTOMER_TO_13_ROWS:\n",
    "#         tmp = train[['customer_ID']].groupby('customer_ID').customer_ID.agg('count')\n",
    "#         more = np.array([],dtype='int64') \n",
    "#         for j in range(1,13):\n",
    "#             i = tmp.loc[tmp==j].index.values\n",
    "#             more = np.concatenate([more,np.repeat(i,13-j)])\n",
    "#         df = train.iloc[:len(more)].copy().fillna(0)\n",
    "#         df = df * 0 - 1 #pad numerical columns with -1\n",
    "#         df[CATS] = (df[CATS] * 0).astype('int8') #pad categorical columns with 0\n",
    "#         df['customer_ID'] = more\n",
    "#         train = pd.concat([train,df],axis=0,ignore_index=True)\n",
    "        \n",
    "    # FILL NAN\n",
    "    #if fill_nan: train = train.fillna(-0.5) #this applies to numerical columns\n",
    "    \n",
    "    # ADD TARGETS (and reduce to 1 byte)\n",
    "#     if targets is not None:\n",
    "#         train = train.merge(targets,on='customer_ID',how='left')\n",
    "#         train.target = train.target.astype('int8')\n",
    "        \n",
    "    # SORT BY CUSTOMER THEN DATE\n",
    "    train = train.sort_values(['customer_ID','year','month','day']).reset_index(drop=True)\n",
    "    train = train.drop(['year','month','day'],axis=1)\n",
    "    \n",
    "    # REARRANGE COLUMNS WITH 11 CATS FIRST\n",
    "    COLS = list(train.columns[1:])\n",
    "    COLS = ['customer_ID'] + CATS + [c for c in COLS if c not in CATS]\n",
    "    train = train[COLS]\n",
    "    \n",
    "    return train\n",
    "\n",
    "\n",
    "def process_stats_for_features(data, data_agg, features, stats_list, num_features_at_a_time = 1):\n",
    "    total_features = len(features)\n",
    "    low_idx = 0\n",
    "    while low_idx < total_features:\n",
    "        high_idx = low_idx + num_features_at_a_time\n",
    "        if (high_idx > total_features):\n",
    "            high_idx = total_features\n",
    "        f = features[low_idx:high_idx]\n",
    "        utils.pt(f'Processing feature/s {f} ... ')\n",
    "        f_e = data.groupby(\"customer_ID\")[f].agg(stats_list)\n",
    "        data.drop(columns=f)\n",
    "        if (data_agg is None):\n",
    "            data_agg = f_e\n",
    "        else:\n",
    "            data_agg = data_agg.merge(f_e, how = 'inner', on = 'customer_ID')\n",
    "        gc.collect()\n",
    "        low_idx = high_idx\n",
    "    return data_agg\n",
    "\n",
    "def feature_engineer_lgbm(data, train_labels = None, fill_nan = False):\n",
    "    utils.pt('Starting training feature engineer 2...')\n",
    "    features = data.drop(['customer_ID'], axis = 1).columns.to_list()\n",
    "    \n",
    "    num_features = [col for col in features if col not in CAT_FEATURES]\n",
    "    cat_features = [col for col in features if col in CAT_FEATURES]\n",
    "    \n",
    "    utils.pt('Processing categorical features ...')\n",
    "    #data_cat_agg = data.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    data_cat_agg = None\n",
    "    data_cat_agg = process_stats_for_features(data, data_cat_agg, cat_features, stats_list = ['count', 'last', 'nunique'], num_features_at_a_time = 3)\n",
    "    utils.pt('Joining aggregate data ...')\n",
    "    data_cat_agg.columns = ['_'.join(x) for x in data_cat_agg.columns]\n",
    "    data_cat_agg.reset_index(inplace = True)\n",
    "    \n",
    "    utils.pt('Processing numerical features ...')\n",
    "    #data_num_agg = data.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    data_num_agg = None\n",
    "    data_num_agg = process_stats_for_features(data, data_num_agg, num_features, stats_list = ['mean', 'std', 'min', 'max', 'last'], num_features_at_a_time = 10)\n",
    "    utils.pt('Joining aggregate data ...')\n",
    "    data_num_agg.columns = ['_'.join(x) for x in data_num_agg.columns]\n",
    "    data_num_agg.reset_index(inplace = True)\n",
    "    \n",
    "    #train_labels = pd.read_feather(FILENAME_TRAIN_PROCESSED2_LABELS_FEATHER)\n",
    "    # data = data_num_agg.merge(_cat_agg, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    # utils.gc_l([data])\n",
    "    \n",
    "    cat_cols = list(data_cat_agg.columns)[1:]  # the first features is customer_ID, so we drop that.\n",
    "    num_cols = list(data_num_agg.columns)[1:]  # the first features is customer_ID, so we drop that.\n",
    "    \n",
    "    utils.pt('Merging numerical and categorical features ...')\n",
    "    \n",
    "    data = data_num_agg.merge(data_cat_agg, how = 'inner', on = 'customer_ID')\n",
    "    if (train_labels is not None):\n",
    "        utils.pt('Merging train labels ...')\n",
    "        data = data.merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    utils.gc_l([data_num_agg, data_cat_agg])\n",
    "    \n",
    "    \n",
    "#    utils.pt('Round last float features to 2 decimal place')\n",
    "    #num_cols = list(data.dtypes[(data.dtypes == 'float32') | (data.dtypes == 'float64')].index)\n",
    "#     num_cols_last = [col for col in num_cols if 'last' in col]\n",
    "#     for col in num_cols_last:\n",
    "#         new_col_name = col + '_round2'\n",
    "#         data[new_col_name] = data[col].round(2)\n",
    "#         num_cols.append(new_col_name)\n",
    "    \n",
    "    # Get feature list\n",
    "    # features = [col for col in data.columns if col not in [CUSTOMER_ID_LABEL, TARGET_LABEL]]\n",
    "    \n",
    "    # fill categorical NaNs with zero. \n",
    "    cat_last_col = [col for col in cat_cols if 'last' in col]\n",
    "    for c in cat_last_col:\n",
    "        data[c] = data[c].fillna(0)\n",
    "    \n",
    "    # fill numerical NaNs with -0.5.\n",
    "#     stats_list = ['mean','min','max', 'last']\n",
    "#     for c in (num_cols):\n",
    "#         if any(substring in c for substring in stats_list):\n",
    "#             data[c] = data[c].fillna(-0.5)\n",
    "#         else:\n",
    "#             data[c] = data[c].fillna(0)\n",
    "    \n",
    "    NUMS_WITH_E = []    \n",
    "    zeros = np.zeros((data.shape[0],), dtype='int8')\n",
    "    ones  = np.ones((data.shape[0],), dtype='int8')\n",
    "    for c in num_cols:\n",
    "        c_exists = c + \"_exists\"\n",
    "        data[c_exists] = np.where(np.invert(np.isnan(data[c].values)), ones, zeros)\n",
    "        data[c] = data[c].fillna(0)\n",
    "        NUMS_WITH_E.append(c)\n",
    "        NUMS_WITH_E.append(c_exists)\n",
    "    \n",
    "    for c in list(data.columns):\n",
    "        if (data[c].isnull().any()):\n",
    "            utils.pt(f'NaN column:{c}')\n",
    "    \n",
    "    cols = ['customer_ID'] + cat_cols + NUMS_WITH_E\n",
    "    \n",
    "    import collections\n",
    "    print([item for item, count in collections.Counter(cols).items() if count > 1])\n",
    "    \n",
    "    return data[cols]\n",
    "\n",
    "# def get_nn_data(lgbm_train, f_list):\n",
    "#     cols = [x for x in lgbm_train.columns if (does_s_begin_with_one_of_l(x, f_list))]    \n",
    "#     nn_train = lgbm_train[cols]\n",
    "    \n",
    "def process_data():\n",
    "    \n",
    "    imp_list, f_p_imp_dict = read_feature_importance()\n",
    "    \n",
    "    imp_f, uimp_f = imp_unimp_features(f_p_imp_dict)\n",
    "    \n",
    "    utils.pt('NN feature engineering')    \n",
    "    # For NN: (1) Get the data of unimportant features.\n",
    "    #         (2) Pre-process data in the same way as for RNN except do not do NaN fill or padding to 13 months.\n",
    "    #         (3) Pre-process data again as though for LGBM, with stats for each column, do a NaN fill as though for RNN.\n",
    "    train_full = pd.read_feather(FILENAME_TRAIN_PROCESSED2_DATA_CAT_NOCHANGE_FEATHER)\n",
    "    cols = ([CUSTOMER_ID_LABEL, TIME_LABEL] + uimp_f)\n",
    "    train_full = train_full.drop(columns=[col for col in train_full if col not in cols])\n",
    "    train_nn = feature_engineer_rnn(train_full,\n",
    "                                    edit_cid_time = False,\n",
    "                                    fill_nan = False,\n",
    "                                    PAD_CUSTOMER_TO_13_ROWS = False,\n",
    "                                    targets = None)\n",
    "    train_nn = feature_engineer_lgbm(train_nn, train_labels = None, fill_nan = True)\n",
    "    \n",
    "    train_nn.to_feather(FILENAME_TRAIN_RNN_NN_DATA_FEATHER)\n",
    "    \n",
    "    utils.gc_l([train_full, train_nn])\n",
    "    \n",
    "    utils.pt('RNN feature engineering')\n",
    "    # For RNN: (1) Get the pre-processed RNN data of important features.\n",
    "    train_full = pd.read_feather(FILENAME_TRAIN_PROCESSED_GRU_NAN_EMBEDDINGS_FEATHER)\n",
    "    cols = ([CUSTOMER_ID_LABEL] + imp_f + [TARGET_LABEL])\n",
    "    train_rnn = train_full.drop(columns=[col for col in train_full if not (any(substring in col for substring in cols))])\n",
    "       \n",
    "    train_rnn.to_feather(FILENAME_TRAIN_RNN_RNN_DATA_FEATHER)\n",
    "    \n",
    "    utils.pt('Feature engineering complete.')\n",
    "    \n",
    "process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076a637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
