{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b075ebe",
   "metadata": {},
   "source": [
    "Inspired by https://www.kaggle.com/code/slowlearnermack/amex-lgbm-dart-cv-0-7963-improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c0794d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "#from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "\n",
    "import utils\n",
    "utils.widen_ipython_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad06c39e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "MAIN_PATH = \"/home/mahesh/Desktop/ML/kaggle/amex/\"\n",
    "\n",
    "# Data\n",
    "PATH_TO_DATA                = MAIN_PATH + \"data/\"\n",
    "PATH_TO_PROCESSED2_DATA     = PATH_TO_DATA + \"processed2/\"\n",
    "PATH_TO_PROCESSED3_DATA     = PATH_TO_DATA + \"processed3/\"\n",
    "PATH_TO_PROCESSED4_DATA     = PATH_TO_DATA + \"processed4/\"\n",
    "\n",
    "\n",
    "# Processed data\n",
    "FILENAME_TRAIN_PROCESSED3_DATA_PARAQUET  = PATH_TO_PROCESSED3_DATA + \"train_data.pq\"\n",
    "FILENAME_TEST_PROCESSED2_DATA_FEATHER    = PATH_TO_PROCESSED2_DATA + \"test_data.f\"\n",
    "FILENAME_TEST_PROCESSED2_LGBM_DATA_FEATHER  = PATH_TO_PROCESSED2_DATA + \"test_LGBM_data.f\"\n",
    "\n",
    "FILENAME_LGBM_SUBMISSION        = PATH_TO_PROCESSED2_DATA + \"submission_lgbm.csv\"\n",
    "FILENAME_LGBM_NEW_CID_SUBMISSION        = PATH_TO_PROCESSED2_DATA + \"submission_lgbm_new_cid.csv\"\n",
    "\n",
    "FILENAME_TEST_CID_OLD_NEW_MAP  = PATH_TO_PROCESSED2_DATA + \"test_cid_old_new_map.f\"\n",
    "\n",
    "\n",
    "# Models\n",
    "PATH_TO_MODEL   = MAIN_PATH + \"models/\"\n",
    "\n",
    "#OOF\n",
    "PATH_TO_OOF = PATH_TO_DATA + \"oof/\"\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "VERBOSE   = 2\n",
    "SEED      = 42\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "TARGET_LABEL      = 'target'\n",
    "CUSTOMER_ID_LABEL = \"customer_ID\"\n",
    "\n",
    "TRAIN_MODEL = 1\n",
    "\n",
    "CAT_FEATURES = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2e8ebb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_features(data, data_agg, features, stats_list, num_features_at_a_time = 1):\n",
    "    total_features = len(features)\n",
    "    low_idx = 0\n",
    "    while low_idx < total_features:\n",
    "        high_idx = low_idx + num_features_at_a_time\n",
    "        if (high_idx > total_features):\n",
    "            high_idx = total_features\n",
    "        f = features[low_idx:high_idx]\n",
    "        utils.pt(f'Processing feature/s {f} ... ')\n",
    "        f_e = data.groupby(\"customer_ID\")[f].agg(stats_list)\n",
    "        data.drop(columns=f)\n",
    "        if (data_agg is None):\n",
    "            data_agg = f_e\n",
    "        else:\n",
    "            data_agg = data_agg.merge(f_e, how = 'inner', on = 'customer_ID')\n",
    "        gc.collect()\n",
    "        low_idx = high_idx\n",
    "    return data_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b71358b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    utils.pt('Starting training feature engineer...')\n",
    "    features = data.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    \n",
    "    num_features = [col for col in features if col not in CAT_FEATURES]\n",
    "    \n",
    "    utils.pt('Processing categorical features ...')\n",
    "    #data_cat_agg = data.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    data_cat_agg = None\n",
    "    data_cat_agg = process_features(data, data_cat_agg, CAT_FEATURES, stats_list = ['count', 'last', 'nunique'], num_features_at_a_time = 3)\n",
    "    utils.pt('Joining aggregate data ...')\n",
    "    data_cat_agg.columns = ['_'.join(x) for x in data_cat_agg.columns]\n",
    "    data_cat_agg.reset_index(inplace = True)\n",
    "    \n",
    "    utils.pt('Processing numerical features ...')\n",
    "    #data_num_agg = data.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    data_num_agg = None\n",
    "    data_num_agg = process_features(data, data_num_agg, num_features, stats_list = ['mean', 'std', 'min', 'max', 'last'], num_features_at_a_time = 10)\n",
    "    utils.pt('Joining aggregate data ...')\n",
    "    data_num_agg.columns = ['_'.join(x) for x in data_num_agg.columns]\n",
    "    data_num_agg.reset_index(inplace = True)\n",
    "    \n",
    "    #train_labels = pd.read_csv('/content/data/train_labels.csv')\n",
    "    #train_labels = pd.read_feather(FILENAME_TRAIN_PROCESSED2_LABELS_FEATHER)\n",
    "    #train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    #del train_num_agg, train_cat_agg\n",
    "    #gc.collect()\n",
    "    \n",
    "    utils.gc_l([data])\n",
    "    \n",
    "    utils.pt('Merging numerical and categorical features ...')\n",
    "    data = data_num_agg.merge(data_cat_agg, how = 'inner', on = 'customer_ID')\n",
    "    utils.gc_l([data_num_agg, data_cat_agg])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb0565a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PREPROCESS_TEST_DATA = 0\n",
    "\n",
    "if PREPROCESS_TEST_DATA:\n",
    "    test_df = pd.read_feather(FILENAME_TEST_PROCESSED2_DATA_FEATHER)\n",
    "    test_df = preprocess_data(test_df)\n",
    "    test_df.info(memory_usage=\"deep\")\n",
    "    test_df.to_feather(FILENAME_TEST_PROCESSED2_LGBM_DATA_FEATHER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "233e1371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test_data(write):\n",
    "\n",
    "    utils.pt('Reading train data')\n",
    "    train = pd.read_parquet(FILENAME_TRAIN_PROCESSED3_DATA_PARAQUET)\n",
    "    \n",
    "    utils.pt('Reading test data')\n",
    "    test = pd.read_feather(FILENAME_TEST_PROCESSED2_LGBM_DATA_FEATHER)\n",
    "    \n",
    "    utils.pt('Label encode categorical features')\n",
    "    cat_features = [f\"{cf}_last\" for cf in CAT_FEATURES]\n",
    "    for cat_col in cat_features:\n",
    "        encoder = LabelEncoder()\n",
    "        train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "        test[cat_col] = encoder.transform(test[cat_col])\n",
    "    \n",
    "    utils.pt('Round last float features to 2 decimal place')\n",
    "    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "    num_cols = [col for col in num_cols if 'last' in col]\n",
    "    for col in num_cols:\n",
    "        #train[col + '_round2'] = train[col].round(2)\n",
    "        test[col + '_round2'] = test[col].round(2)\n",
    "    # Get feature list\n",
    "    features = [col for col in test.columns if col not in [CUSTOMER_ID_LABEL, TARGET_LABEL]]\n",
    "    \n",
    "    utils.gc_l([train])\n",
    "    \n",
    "    # Create a numpy array to store test predictions\n",
    "    test_predictions = np.zeros(len(test))\n",
    "    \n",
    "    test_preds_list = []\n",
    "    \n",
    "    for fold in range(NUM_FOLDS):\n",
    "        utils.pt(f'Predicting for test data using LGBM model for fold {fold}')\n",
    "        # load lgbm model\n",
    "        model = joblib.load(f'{PATH_TO_MODEL}lgbm_fold{fold}_seed{SEED}.pkl')\n",
    "        \n",
    "        test_pred = model.predict(test[features])\n",
    "        #test_predictions += test_pred / NUM_FOLDS\n",
    "        test_predictions += test_pred\n",
    "        \n",
    "        test_preds_list.append(test_pred)\n",
    "        \n",
    "    test_predictions = test_predictions / NUM_FOLDS\n",
    "    # Create a dataframe to store test prediction\n",
    "    test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "    if write: \n",
    "        test_df.to_csv(FILENAME_LGBM_NEW_CID_SUBMISSION, index = False)\n",
    "    \n",
    "    return test_preds_list\n",
    "\n",
    "EVALUATE_TEST_DATA = 0\n",
    "\n",
    "if EVALUATE_TEST_DATA:\n",
    "    test_preds_list = evaluate_test_data(write=False)\n",
    "    test_df.info()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c7849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE_SUBMISSION_FILE = 0\n",
    "if WRITE_SUBMISSION_FILE:\n",
    "    test_df = pd.read_csv(FILENAME_LGBM_NEW_CID_SUBMISSION)\n",
    "    test_cids = pd.read_feather(FILENAME_TEST_CID_OLD_NEW_MAP)\n",
    "    test_df = test_df.merge(test_cids,how = 'inner', on = 'customer_ID')\n",
    "    test_df.drop(columns=['customer_ID'], inplace = True)\n",
    "    test_df.rename(columns = {'customer_ID_orig':'customer_ID'}, inplace = True)\n",
    "    test_df = test_df[['customer_ID', 'prediction']]\n",
    "    test_df.to_csv(FILENAME_LGBM_SUBMISSION, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95ec27c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "def read_data():\n",
    "    train = pd.read_parquet(FILENAME_TRAIN_PROCESSED3_DATA_PARAQUET)\n",
    "    #test = pd.read_parquet(CFG.input_dir + 'test_fe.parquet')\n",
    "    test = []\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def extract_X_Y(FE_data, features, cids):\n",
    "    #utils.pt(str(FE_data.shape))\n",
    "    #utils.pt(str(cids.shape))\n",
    "    \n",
    "    data = FE_data.loc[(FE_data.customer_ID.isin(cids.customer_ID.values))]\n",
    "    data = data.reset_index() # this adds \"index\" column to the data-frame\n",
    "    \n",
    "    #utils.pt(str(data.shape))\n",
    "    #data.info()\n",
    "    #utils.pt(str(data.columns))\n",
    "    \n",
    "    Y = data[TARGET_LABEL]\n",
    "    X = data[features]\n",
    "    \n",
    "    return (X,Y)\n",
    "\n",
    "def extract_val_train_data(fold, train_FE_data, features):\n",
    "    train_cids = pd.read_feather(f'{PATH_TO_PROCESSED4_DATA}/train_{CUSTOMER_ID_LABEL}_fold_{fold}.f')\n",
    "    val_cids   = pd.read_feather(f'{PATH_TO_PROCESSED4_DATA}/val_{CUSTOMER_ID_LABEL}_fold_{fold}.f')\n",
    "    \n",
    "    (X_train, Y_train) = extract_X_Y(train_FE_data, features, train_cids) \n",
    "    (X_val  , Y_val  ) = extract_X_Y(train_FE_data, features, val_cids  )\n",
    "    \n",
    "    return (X_train, Y_train, X_val, Y_val)\n",
    "\n",
    "def extract_test_data(train_FE_data, features):\n",
    "    test_cids = pd.read_feather(f'{PATH_TO_PROCESSED4_DATA}/test_{CUSTOMER_ID_LABEL}.f')\n",
    "    return (extract_X_Y(train_FE_data, features, test_cids))\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Train & Evaluate\n",
    "# ====================================================\n",
    "def train_and_evaluate(train, test):\n",
    "    # Label encode categorical features\n",
    "    cat_features = [f\"{cf}_last\" for cf in CAT_FEATURES]\n",
    "    for cat_col in cat_features:\n",
    "        encoder = LabelEncoder()\n",
    "        train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "        #test[cat_col] = encoder.transform(test[cat_col])\n",
    "    # Round last float features to 2 decimal place\n",
    "    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "    num_cols = [col for col in num_cols if 'last' in col]\n",
    "    for col in num_cols:\n",
    "        train[col + '_round2'] = train[col].round(2)\n",
    "        #test[col + '_round2'] = test[col].round(2)\n",
    "    # Get feature list\n",
    "    features = [col for col in train.columns if col not in [CUSTOMER_ID_LABEL, TARGET_LABEL]]\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': \"binary_logloss\",\n",
    "        'boosting': 'dart',\n",
    "        'seed': SEED,\n",
    "        'num_leaves': 100,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.20,\n",
    "        'bagging_freq': 10,\n",
    "        'bagging_fraction': 0.50,\n",
    "        'n_jobs': -1,\n",
    "        'lambda_l2': 2,\n",
    "        'min_data_in_leaf': 40,\n",
    "        'saved_feature_importance_type' : 1\n",
    "        }\n",
    "    # Create a numpy array to store test predictions\n",
    "    test_predictions = np.zeros(len(test))\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train))\n",
    "    #kfold = StratifiedKFold(n_splits = NUM_FOLDS, shuffle = True, random_state = SEED)\n",
    "    #for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[TARGET_LABEL])):\n",
    "    (x_test, y_test) = extract_test_data(train, features)\n",
    "    #for fold in range(0,NUM_FOLDS):\n",
    "    for fold in range(0,1):\n",
    "        print(' ')\n",
    "        print('-'*50)\n",
    "        utils.pt(f'Training fold {fold} with {len(features)} features...')\n",
    "        (x_train, y_train, x_val, y_val) = extract_val_train_data(fold, train, features)\n",
    "        #x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "        #y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "        model = lgb.train(\n",
    "            params = params,\n",
    "            train_set = lgb_train,\n",
    "            num_boost_round = 10500,\n",
    "            valid_sets = [lgb_train, lgb_valid],\n",
    "            #valid_sets = [lgb_valid],\n",
    "            early_stopping_rounds = 100,\n",
    "            verbose_eval = 500,\n",
    "            feval = utils.lgb_amex_metric,\n",
    "            \n",
    "            )\n",
    "        # Save best model\n",
    "        joblib.dump(model, f'{PATH_TO_MODEL}lgbm_fold{fold}_seed{SEED}.pkl')\n",
    "        # Predict validation\n",
    "        val_pred = model.predict(x_val)\n",
    "        # Add to out of folds array\n",
    "        #oof_predictions[val_ind] = val_pred\n",
    "        # Predict the test set\n",
    "#         test_pred = model.predict(test[features])\n",
    "#         test_predictions += test_pred / CFG.n_folds\n",
    "        # Compute fold metric\n",
    "        score = utils.amex_metric(y_val, val_pred)\n",
    "        utils.pt(f'Our fold {fold} CV score is {score}')\n",
    "        \n",
    "        test_pred = model.predict(x_test)\n",
    "        score = utils.amex_metric(y_test, test_pred)\n",
    "        utils.pt(f'Our fold {fold} Test score is {score}')\n",
    "        \n",
    "        utils.gc_l([x_train, x_val, y_train, y_val, lgb_train, lgb_valid])\n",
    "        \n",
    "    # Compute out of folds metric\n",
    "    #score = amex_metric(train[TARGET_LABEL], oof_predictions)\n",
    "    #utils.pt(f'Our out of folds CV score is {score}')\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    #oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[TARGET_LABEL], 'prediction': oof_predictions})\n",
    "    #oof_df.to_csv(f'{PATH_TO_OOF}oof_lgbm_baseline_{NUM_FOLDS}fold_seed{SEED}.csv', index = False)\n",
    "    # Create a dataframe to store test prediction\n",
    "    #test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "    #test_df.to_csv(f'/content/drive/MyDrive/Amex/Predictions/test_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92bec341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "2022-08-30 13:16:32.578175 : Training fold 0 with 1094 features...\n",
      "[LightGBM] [Info] Number of positive: 90309, number of negative: 258464\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.984192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 241147\n",
      "[LightGBM] [Info] Number of data points in the train set: 348773, number of used features: 1093\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051519\n",
      "[LightGBM] [Info] Start training from score -1.051519\n",
      "[500]\ttraining's binary_logloss: 0.337449\ttraining's amex_metric: 0.777646\tvalid_1's binary_logloss: 0.338931\tvalid_1's amex_metric: 0.771833\n",
      "[1000]\ttraining's binary_logloss: 0.246641\ttraining's amex_metric: 0.794261\tvalid_1's binary_logloss: 0.251325\tvalid_1's amex_metric: 0.780651\n",
      "[1500]\ttraining's binary_logloss: 0.222451\ttraining's amex_metric: 0.809052\tvalid_1's binary_logloss: 0.231105\tvalid_1's amex_metric: 0.787661\n",
      "[2000]\ttraining's binary_logloss: 0.20861\ttraining's amex_metric: 0.822097\tvalid_1's binary_logloss: 0.222444\tvalid_1's amex_metric: 0.792108\n",
      "[2500]\ttraining's binary_logloss: 0.201421\ttraining's amex_metric: 0.832494\tvalid_1's binary_logloss: 0.219689\tvalid_1's amex_metric: 0.794479\n",
      "[3000]\ttraining's binary_logloss: 0.194191\ttraining's amex_metric: 0.84296\tvalid_1's binary_logloss: 0.217478\tvalid_1's amex_metric: 0.795454\n",
      "[3500]\ttraining's binary_logloss: 0.187441\ttraining's amex_metric: 0.853693\tvalid_1's binary_logloss: 0.215982\tvalid_1's amex_metric: 0.796468\n",
      "[4000]\ttraining's binary_logloss: 0.181472\ttraining's amex_metric: 0.863882\tvalid_1's binary_logloss: 0.215126\tvalid_1's amex_metric: 0.796375\n",
      "[4500]\ttraining's binary_logloss: 0.175632\ttraining's amex_metric: 0.873852\tvalid_1's binary_logloss: 0.214448\tvalid_1's amex_metric: 0.797477\n",
      "[5000]\ttraining's binary_logloss: 0.169836\ttraining's amex_metric: 0.883896\tvalid_1's binary_logloss: 0.213967\tvalid_1's amex_metric: 0.797206\n",
      "[5500]\ttraining's binary_logloss: 0.164633\ttraining's amex_metric: 0.892699\tvalid_1's binary_logloss: 0.213596\tvalid_1's amex_metric: 0.797176\n",
      "[6000]\ttraining's binary_logloss: 0.160196\ttraining's amex_metric: 0.901024\tvalid_1's binary_logloss: 0.213418\tvalid_1's amex_metric: 0.797453\n",
      "[6500]\ttraining's binary_logloss: 0.155512\ttraining's amex_metric: 0.908326\tvalid_1's binary_logloss: 0.213181\tvalid_1's amex_metric: 0.797752\n",
      "[7000]\ttraining's binary_logloss: 0.150119\ttraining's amex_metric: 0.917067\tvalid_1's binary_logloss: 0.212957\tvalid_1's amex_metric: 0.798407\n",
      "[7500]\ttraining's binary_logloss: 0.144988\ttraining's amex_metric: 0.925493\tvalid_1's binary_logloss: 0.212777\tvalid_1's amex_metric: 0.798394\n",
      "[8000]\ttraining's binary_logloss: 0.140413\ttraining's amex_metric: 0.932919\tvalid_1's binary_logloss: 0.212687\tvalid_1's amex_metric: 0.79947\n",
      "[8500]\ttraining's binary_logloss: 0.13654\ttraining's amex_metric: 0.939689\tvalid_1's binary_logloss: 0.212646\tvalid_1's amex_metric: 0.799611\n",
      "[9000]\ttraining's binary_logloss: 0.132154\ttraining's amex_metric: 0.94587\tvalid_1's binary_logloss: 0.212524\tvalid_1's amex_metric: 0.799504\n",
      "[9500]\ttraining's binary_logloss: 0.128241\ttraining's amex_metric: 0.952038\tvalid_1's binary_logloss: 0.212508\tvalid_1's amex_metric: 0.799367\n",
      "[10000]\ttraining's binary_logloss: 0.124399\ttraining's amex_metric: 0.957113\tvalid_1's binary_logloss: 0.212482\tvalid_1's amex_metric: 0.800343\n",
      "[10500]\ttraining's binary_logloss: 0.121037\ttraining's amex_metric: 0.961765\tvalid_1's binary_logloss: 0.212418\tvalid_1's amex_metric: 0.799784\n",
      "2022-08-30 14:26:42.852560 : Our fold 0 CV score is 0.7997838044660651\n",
      "2022-08-30 14:26:46.935531 : Our fold 0 Test score is 0.8003464241561005\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if TRAIN_MODEL:\n",
    "    seed_everything(SEED)\n",
    "    train, test = read_data()\n",
    "    train_and_evaluate(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd1bed81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('D_87_std', 458441), ('D_87_mean', 458084), ('D_87_min', 458084), ('D_87_max', 458084), ('D_87_last', 458084), ('D_87_last_round2', 458084), ('D_88_std', 456929), ('D_88_mean', 456494), ('D_88_min', 456494), ('D_88_max', 456494), ('D_88_last', 456494), ('D_88_last_round2', 456494), ('D_110_std', 454994), ('D_111_std', 454994), ('B_39_std', 454964), ('D_110_mean', 454826), ('D_110_min', 454826), ('D_110_max', 454826), ('D_110_last', 454826), ('D_111_mean', 454826), ('D_111_min', 454826), ('D_111_max', 454826), ('D_111_last', 454826), ('D_110_last_round2', 454826), ('D_111_last_round2', 454826), ('B_39_mean', 454807), ('B_39_min', 454807), ('B_39_max', 454807), ('B_39_last', 454807), ('B_39_last_round2', 454807), ('D_108_std', 452822), ('B_42_std', 452592), ('B_42_mean', 452404), ('B_42_min', 452404), ('B_42_max', 452404), ('B_42_last', 452404), ('B_42_last_round2', 452404), ('D_73_std', 451403), ('D_73_mean', 450905), ('D_73_min', 450905), ('D_73_max', 450905), ('D_73_last', 450905), ('D_73_last_round2', 450905), ('D_108_mean', 437983), ('D_108_min', 437983), ('D_108_max', 437983), ('D_108_last', 437983), ('D_108_last_round2', 437983), ('D_134_std', 426941), ('D_135_std', 426941), ('D_136_std', 426941), ('D_137_std', 426941), ('D_138_std', 426941), ('D_134_mean', 424357), ('D_134_min', 424357), ('D_134_max', 424357), ('D_134_last', 424357), ('D_135_mean', 424357), ('D_135_min', 424357), ('D_135_max', 424357), ('D_135_last', 424357), ('D_136_mean', 424357), ('D_136_min', 424357), ('D_136_max', 424357), ('D_136_last', 424357), ('D_137_mean', 424357), ('D_137_min', 424357), ('D_137_max', 424357), ('D_137_last', 424357), ('D_138_mean', 424357), ('D_138_min', 424357), ('D_138_max', 424357), ('D_138_last', 424357), ('D_134_last_round2', 424357), ('D_135_last_round2', 424357), ('D_136_last_round2', 424357), ('D_137_last_round2', 424357), ('D_138_last_round2', 424357), ('B_29_std', 422892), ('R_9_std', 422824), ('B_29_mean', 422100), ('B_29_min', 422100), ('B_29_max', 422100), ('B_29_last', 422100), ('B_29_last_round2', 422100), ('R_9_mean', 419377), ('R_9_min', 419377), ('R_9_max', 419377), ('R_9_last', 419377), ('R_9_last_round2', 419377), ('R_26_std', 407666), ('R_26_mean', 407647), ('R_26_min', 407647), ('R_26_max', 407647), ('R_26_last', 407647), ('R_26_last_round2', 407647), ('D_76_std', 404419), ('D_76_mean', 402992), ('D_76_min', 402992), ('D_76_max', 402992), ('D_76_last', 402992), ('D_76_last_round2', 402992), ('D_106_std', 401585), ('D_132_std', 401507), ('D_49_std', 401500), ('D_106_mean', 397376), ('D_106_min', 397376), ('D_106_max', 397376), ('D_106_last', 397376), ('D_106_last_round2', 397376), ('D_132_mean', 397300), ('D_132_min', 397300), ('D_132_max', 397300), ('D_132_last', 397300), ('D_132_last_round2', 397300), ('D_49_mean', 397298), ('D_49_min', 397298), ('D_49_max', 397298), ('D_49_last', 397298), ('D_49_last_round2', 397298), ('D_142_std', 375515), ('D_142_mean', 373333), ('D_142_min', 373333), ('D_142_max', 373333), ('D_142_last', 373333), ('D_142_last_round2', 373333), ('D_42_std', 353118), ('D_42_mean', 345389), ('D_42_min', 345389), ('D_42_max', 345389), ('D_42_last', 345389), ('D_42_last_round2', 345389), ('D_82_std', 337224), ('D_82_mean', 335428), ('D_82_min', 335428), ('D_82_max', 335428), ('D_82_last', 335428), ('D_82_last_round2', 335428), ('D_53_std', 321952), ('D_53_mean', 314857), ('D_53_min', 314857), ('D_53_max', 314857), ('D_53_last', 314857), ('D_53_last_round2', 314857), ('D_50_std', 253234), ('D_50_mean', 249021), ('D_50_min', 249021), ('D_50_max', 249021), ('D_50_last', 249021), ('D_50_last_round2', 249021), ('D_105_std', 229395), ('D_56_std', 224196), ('B_17_std', 222285), ('D_105_mean', 222059), ('D_105_min', 222059), ('D_105_max', 222059), ('D_105_last', 222059), ('D_105_last_round2', 222059), ('D_56_mean', 214314), ('D_56_min', 214314), ('D_56_max', 214314), ('D_56_last', 214314), ('D_56_last_round2', 214314), ('B_17_mean', 213430), ('B_17_min', 213430), ('B_17_max', 213430), ('B_17_last', 213430), ('B_17_last_round2', 213430), ('S_9_std', 187852), ('S_9_mean', 145234), ('S_9_min', 145234), ('S_9_max', 145234), ('S_9_last', 145234), ('S_9_last_round2', 145234), ('D_77_std', 119485), ('D_43_std', 111675), ('D_43_mean', 103075), ('D_43_min', 103075), ('D_43_max', 103075), ('D_43_last', 103075), ('D_43_last_round2', 103075), ('D_77_mean', 90688), ('D_77_min', 90688), ('D_77_max', 90688), ('D_77_last', 90688), ('D_77_last_round2', 90688), ('D_46_std', 87225), ('D_46_mean', 79968), ('D_46_min', 79968), ('D_46_max', 79968), ('D_46_last', 79968), ('D_46_last_round2', 79968), ('S_27_std', 74686), ('S_27_mean', 65737), ('S_27_min', 65737), ('S_27_max', 65737), ('S_27_last', 65737), ('S_27_last_round2', 65737), ('S_3_std', 63446), ('S_7_std', 63446), ('S_3_mean', 56596), ('S_3_min', 56596), ('S_3_max', 56596), ('S_3_last', 56596), ('S_7_mean', 56596), ('S_7_min', 56596), ('S_7_max', 56596), ('S_7_last', 56596), ('S_3_last_round2', 56596), ('S_7_last_round2', 56596), ('D_62_std', 40169), ('D_48_std', 38094), ('D_61_std', 30434), ('D_62_mean', 30350), ('D_62_min', 30350), ('D_62_max', 30350), ('D_62_last', 30350), ('D_62_last_round2', 30350), ('D_48_mean', 28816), ('D_48_min', 28816), ('D_48_max', 28816), ('D_48_last', 28816), ('D_48_last_round2', 28816), ('R_27_std', 27187), ('R_27_mean', 26988), ('R_27_min', 26988), ('R_27_max', 26988), ('R_27_last', 26988), ('R_27_last_round2', 26988), ('P_3_std', 26658), ('D_69_std', 23459), ('D_83_std', 23459), ('D_113_std', 23335), ('D_115_std', 23335), ('D_118_std', 23335), ('D_119_std', 23335), ('D_121_std', 23335), ('D_122_std', 23335), ('D_123_std', 23335), ('D_124_std', 23335), ('D_125_std', 23335), ('D_44_std', 23325), ('D_78_std', 23325), ('P_3_mean', 21526), ('P_3_min', 21526), ('P_3_max', 21526), ('P_3_last', 21526), ('P_3_last_round2', 21526), ('D_61_mean', 21083), ('D_61_min', 21083), ('D_61_max', 21083), ('D_61_last', 21083), ('D_61_last_round2', 21083), ('D_91_std', 19606), ('D_44_mean', 17565), ('D_44_min', 17565), ('D_44_max', 17565), ('D_44_last', 17565), ('D_78_mean', 17565), ('D_78_min', 17565), ('D_78_max', 17565), ('D_78_last', 17565), ('D_44_last_round2', 17565), ('D_78_last_round2', 17565), ('D_59_std', 13083), ('D_91_mean', 12785), ('D_91_min', 12785), ('D_91_max', 12785), ('D_91_last', 12785), ('D_91_last_round2', 12785), ('D_70_std', 11966), ('D_103_std', 9101), ('D_104_std', 9101), ('D_107_std', 9101), ('D_128_std', 9101), ('D_129_std', 9101), ('D_130_std', 9101), ('D_131_std', 9101), ('D_139_std', 9101), ('D_141_std', 9101), ('D_143_std', 9101), ('D_145_std', 9101), ('D_79_std', 9086), ('D_55_std', 8018), ('P_2_std', 7829), ('B_13_std', 7777), ('D_74_std', 7576), ('D_80_std', 7576), ('B_8_std', 6733), ('D_52_std', 6412), ('D_84_std', 6412), ('D_89_std', 6412), ('D_72_std', 6379), ('D_81_std', 6168), ('B_15_std', 5719), ('B_25_std', 5719), ('S_22_std', 5304), ('S_24_std', 5296), ('B_2_std', 5212), ('D_41_std', 5212), ('B_3_std', 5212), ('D_45_std', 5212), ('B_6_std', 5212), ('D_54_std', 5212), ('B_16_std', 5212), ('B_19_std', 5212), ('B_20_std', 5212), ('B_22_std', 5212), ('B_26_std', 5212), ('B_27_std', 5212), ('B_33_std', 5212), ('D_109_std', 5212), ('D_112_std', 5212), ('S_25_std', 5199), ('D_102_std', 5181), ('D_133_std', 5181), ('D_140_std', 5181), ('D_144_std', 5181), ('S_23_std', 5121), ('D_39_std', 5120), ('B_1_std', 5120), ('R_1_std', 5120), ('B_4_std', 5120), ('B_5_std', 5120), ('R_2_std', 5120), ('D_47_std', 5120), ('B_7_std', 5120), ('D_51_std', 5120), ('B_9_std', 5120), ('R_3_std', 5120), ('B_10_std', 5120), ('S_5_std', 5120), ('B_11_std', 5120), ('S_6_std', 5120), ('R_4_std', 5120), ('B_12_std', 5120), ('S_8_std', 5120), ('R_5_std', 5120), ('D_58_std', 5120), ('B_14_std', 5120), ('D_60_std', 5120), ('S_11_std', 5120), ('D_65_std', 5120), ('B_18_std', 5120), ('S_12_std', 5120), ('R_6_std', 5120), ('S_13_std', 5120), ('B_21_std', 5120), ('D_71_std', 5120), ('S_15_std', 5120), ('B_23_std', 5120), ('P_4_std', 5120), ('D_75_std', 5120), ('B_24_std', 5120), ('R_7_std', 5120), ('R_8_std', 5120), ('S_16_std', 5120), ('R_10_std', 5120), ('R_11_std', 5120), ('S_17_std', 5120), ('R_12_std', 5120), ('B_28_std', 5120), ('R_13_std', 5120), ('R_14_std', 5120), ('R_15_std', 5120), ('R_16_std', 5120), ('S_18_std', 5120), ('D_86_std', 5120), ('R_17_std', 5120), ('R_18_std', 5120), ('B_31_std', 5120), ('S_19_std', 5120), ('R_19_std', 5120), ('B_32_std', 5120), ('S_20_std', 5120), ('R_20_std', 5120), ('R_21_std', 5120), ('R_22_std', 5120), ('R_23_std', 5120), ('D_92_std', 5120), ('D_93_std', 5120), ('D_94_std', 5120), ('R_24_std', 5120), ('R_25_std', 5120), ('D_96_std', 5120), ('S_26_std', 5120), ('B_36_std', 5120), ('B_37_std', 5120), ('B_40_std', 5120), ('D_127_std', 5120), ('B_41_std', 5120), ('R_28_std', 5120), ('D_69_mean', 4787), ('D_69_min', 4787), ('D_69_max', 4787), ('D_69_last', 4787), ('D_83_mean', 4787), ('D_83_min', 4787), ('D_83_max', 4787), ('D_83_last', 4787), ('D_69_last_round2', 4787), ('D_83_last_round2', 4787), ('D_113_mean', 4739), ('D_113_min', 4739), ('D_113_max', 4739), ('D_113_last', 4739), ('D_115_mean', 4739), ('D_115_min', 4739), ('D_115_max', 4739), ('D_115_last', 4739), ('D_118_mean', 4739), ('D_118_min', 4739), ('D_118_max', 4739), ('D_118_last', 4739), ('D_119_mean', 4739), ('D_119_min', 4739), ('D_119_max', 4739), ('D_119_last', 4739), ('D_121_mean', 4739), ('D_121_min', 4739), ('D_121_max', 4739), ('D_121_last', 4739), ('D_122_mean', 4739), ('D_122_min', 4739), ('D_122_max', 4739), ('D_122_last', 4739), ('D_123_mean', 4739), ('D_123_min', 4739), ('D_123_max', 4739), ('D_123_last', 4739), ('D_124_mean', 4739), ('D_124_min', 4739), ('D_124_max', 4739), ('D_124_last', 4739), ('D_125_mean', 4739), ('D_125_min', 4739), ('D_125_max', 4739), ('D_125_last', 4739), ('D_113_last_round2', 4739), ('D_115_last_round2', 4739), ('D_118_last_round2', 4739), ('D_119_last_round2', 4739), ('D_121_last_round2', 4739), ('D_122_last_round2', 4739), ('D_123_last_round2', 4739), ('D_124_last_round2', 4739), ('D_125_last_round2', 4739), ('D_70_mean', 4118), ('D_70_min', 4118), ('D_70_max', 4118), ('D_70_last', 4118), ('D_70_last_round2', 4118), ('D_59_mean', 3796), ('D_59_min', 3796), ('D_59_max', 3796), ('D_59_last', 3796), ('D_59_last_round2', 3796), ('B_8_mean', 2979), ('B_8_min', 2979), ('B_8_max', 2979), ('B_8_last', 2979), ('B_8_last_round2', 2979), ('D_103_mean', 2532), ('D_103_min', 2532), ('D_103_max', 2532), ('D_103_last', 2532), ('D_104_mean', 2532), ('D_104_min', 2532), ('D_104_max', 2532), ('D_104_last', 2532), ('D_107_mean', 2532), ('D_107_min', 2532), ('D_107_max', 2532), ('D_107_last', 2532), ('D_128_mean', 2532), ('D_128_min', 2532), ('D_128_max', 2532), ('D_128_last', 2532), ('D_129_mean', 2532), ('D_129_min', 2532), ('D_129_max', 2532), ('D_129_last', 2532), ('D_130_mean', 2532), ('D_130_min', 2532), ('D_130_max', 2532), ('D_130_last', 2532), ('D_131_mean', 2532), ('D_131_min', 2532), ('D_131_max', 2532), ('D_131_last', 2532), ('D_139_mean', 2532), ('D_139_min', 2532), ('D_139_max', 2532), ('D_139_last', 2532), ('D_141_mean', 2532), ('D_141_min', 2532), ('D_141_max', 2532), ('D_141_last', 2532), ('D_143_mean', 2532), ('D_143_min', 2532), ('D_143_max', 2532), ('D_143_last', 2532), ('D_145_mean', 2532), ('D_145_min', 2532), ('D_145_max', 2532), ('D_145_last', 2532), ('D_103_last_round2', 2532), ('D_104_last_round2', 2532), ('D_107_last_round2', 2532), ('D_128_last_round2', 2532), ('D_129_last_round2', 2532), ('D_130_last_round2', 2532), ('D_131_last_round2', 2532), ('D_139_last_round2', 2532), ('D_141_last_round2', 2532), ('D_143_last_round2', 2532), ('D_145_last_round2', 2532), ('D_79_mean', 2519), ('D_79_min', 2519), ('D_79_max', 2519), ('D_79_last', 2519), ('D_79_last_round2', 2519), ('D_55_mean', 2478), ('D_55_min', 2478), ('D_55_max', 2478), ('D_55_last', 2478), ('D_55_last_round2', 2478), ('P_2_mean', 2434), ('P_2_min', 2434), ('P_2_max', 2434), ('P_2_last', 2434), ('P_2_last_round2', 2434), ('D_74_mean', 1595), ('D_74_min', 1595), ('D_74_max', 1595), ('D_74_last', 1595), ('D_80_mean', 1595), ('D_80_min', 1595), ('D_80_max', 1595), ('D_80_last', 1595), ('D_74_last_round2', 1595), ('D_80_last_round2', 1595), ('B_13_mean', 1563), ('B_13_min', 1563), ('B_13_max', 1563), ('B_13_last', 1563), ('B_13_last_round2', 1563), ('D_52_mean', 1143), ('D_52_min', 1143), ('D_52_max', 1143), ('D_52_last', 1143), ('D_84_mean', 1143), ('D_84_min', 1143), ('D_84_max', 1143), ('D_84_last', 1143), ('D_89_mean', 1143), ('D_89_min', 1143), ('D_89_max', 1143), ('D_89_last', 1143), ('D_52_last_round2', 1143), ('D_84_last_round2', 1143), ('D_89_last_round2', 1143), ('D_72_mean', 1128), ('D_72_min', 1128), ('D_72_max', 1128), ('D_72_last', 1128), ('D_72_last_round2', 1128), ('D_81_mean', 902), ('D_81_min', 902), ('D_81_max', 902), ('D_81_last', 902), ('D_81_last_round2', 902), ('B_15_mean', 604), ('B_15_min', 604), ('B_15_max', 604), ('B_15_last', 604), ('B_25_mean', 604), ('B_25_min', 604), ('B_25_max', 604), ('B_25_last', 604), ('B_15_last_round2', 604), ('B_25_last_round2', 604), ('S_22_mean', 118), ('S_22_min', 118), ('S_22_max', 118), ('S_22_last', 118), ('S_22_last_round2', 118), ('S_24_mean', 117), ('S_24_min', 117), ('S_24_max', 117), ('S_24_last', 117), ('S_24_last_round2', 117), ('S_25_mean', 45), ('S_25_min', 45), ('S_25_max', 45), ('S_25_last', 45), ('S_25_last_round2', 45), ('B_6_mean', 40), ('B_6_min', 40), ('B_6_max', 40), ('B_6_last', 40), ('B_6_last_round2', 40), ('B_2_mean', 31), ('B_2_min', 31), ('B_2_max', 31), ('B_2_last', 31), ('D_41_mean', 31), ('D_41_min', 31), ('D_41_max', 31), ('D_41_last', 31), ('B_3_mean', 31), ('B_3_min', 31), ('B_3_max', 31), ('B_3_last', 31), ('D_45_mean', 31), ('D_45_min', 31), ('D_45_max', 31), ('D_45_last', 31), ('D_54_mean', 31), ('D_54_min', 31), ('D_54_max', 31), ('D_54_last', 31), ('B_16_mean', 31), ('B_16_min', 31), ('B_16_max', 31), ('B_16_last', 31), ('B_19_mean', 31), ('B_19_min', 31), ('B_19_max', 31), ('B_19_last', 31), ('B_20_mean', 31), ('B_20_min', 31), ('B_20_max', 31), ('B_20_last', 31), ('B_22_mean', 31), ('B_22_min', 31), ('B_22_max', 31), ('B_22_last', 31), ('B_26_mean', 31), ('B_26_min', 31), ('B_26_max', 31), ('B_26_last', 31), ('B_27_mean', 31), ('B_27_min', 31), ('B_27_max', 31), ('B_27_last', 31), ('B_33_mean', 31), ('B_33_min', 31), ('B_33_max', 31), ('B_33_last', 31), ('D_109_mean', 31), ('D_109_min', 31), ('D_109_max', 31), ('D_109_last', 31), ('D_112_mean', 31), ('D_112_min', 31), ('D_112_max', 31), ('D_112_last', 31), ('B_2_last_round2', 31), ('D_41_last_round2', 31), ('B_3_last_round2', 31), ('D_45_last_round2', 31), ('D_54_last_round2', 31), ('B_16_last_round2', 31), ('B_19_last_round2', 31), ('B_20_last_round2', 31), ('B_22_last_round2', 31), ('B_26_last_round2', 31), ('B_27_last_round2', 31), ('B_33_last_round2', 31), ('D_109_last_round2', 31), ('D_112_last_round2', 31), ('S_23_mean', 1), ('S_23_min', 1), ('S_23_max', 1), ('S_23_last', 1), ('S_23_last_round2', 1)]\n"
     ]
    }
   ],
   "source": [
    "nan_cols = [(i,train[i].isna().sum()) for i in train.columns if train[i].isnull().any()]\n",
    "nan_cols.sort(key = (lambda x: x[1]), reverse = True)\n",
    "print((nan_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f4bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
